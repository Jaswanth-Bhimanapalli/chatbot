{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_labels = ['About Class', 'Exam Details', 'Greetings', 'Project Details', 'Syllabus', 'Valediction', 'Professor Name', 'Office Hours', 'Office Location', 'Lecture Timings', 'Lecture Location', 'Class Location']\n",
    "dataframe = pd.read_table(\"professorName.txt\", header=None)\n",
    "dataframe['class'] = 6\n",
    "train_data = dataframe\n",
    "#print train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframe = pd.read_table(\"officeHours.txt\", header=None)\n",
    "dataframe['class'] = 7 #'Office Hours'#1\n",
    "train_data = train_data.append(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframe = pd.read_table(\"officeLocation.txt\", header=None)\n",
    "dataframe['class'] = 8 #'Office Location'#2\n",
    "train_data = train_data.append(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframe = pd.read_table(\"lectureTimings.txt\", header=None)\n",
    "dataframe['class'] = 9 #'Lecture Timings'#3\n",
    "train_data = train_data.append(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframe = pd.read_table(\"lectureLocation.txt\", header=None)\n",
    "dataframe['class'] = 10 #'Lecture Location'#4\n",
    "train_data = train_data.append(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframe = pd.read_table(\"classLocation.txt\", header=None)\n",
    "dataframe['class'] = 11 #'Class Location'#5\n",
    "train_data = train_data.append(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframe = pd.read_table(\"aboutClass.txt\", header=None)\n",
    "dataframe['class'] = 0\n",
    "train_data = train_data.append(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframe = pd.read_table(\"examDetails.txt\", header=None)\n",
    "dataframe['class'] = 1\n",
    "train_data = train_data.append(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframe = pd.read_table(\"greetings.txt\", header=None)\n",
    "dataframe['class'] = 2\n",
    "train_data = train_data.append(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframe = pd.read_table(\"projectDetails.txt\", header=None)\n",
    "dataframe['class'] = 3\n",
    "train_data = train_data.append(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframe = pd.read_table(\"syllabus.txt\", header=None)\n",
    "dataframe['class'] = 4\n",
    "train_data = train_data.append(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframe = pd.read_table(\"valediction.txt\", header=None)\n",
    "dataframe['class'] = 5\n",
    "train_data = train_data.append(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     0  class\n",
      "0                                       name professor      6\n",
      "1                                        name lecturer      6\n",
      "2                                      name instructor      6\n",
      "3                                         name teacher      6\n",
      "4                                   name the professor      6\n",
      "5                                    name the lecturer      6\n",
      "6                                  name the instructor      6\n",
      "7                                     name the teacher      6\n",
      "8                                    name of professor      6\n",
      "9                                     name of lecturer      6\n",
      "10                                  name of instructor      6\n",
      "11                                     name of teacher      6\n",
      "12                               name of the professor      6\n",
      "13                                name of the lecturer      6\n",
      "14                              name of the instructor      6\n",
      "15                                 name of the teacher      6\n",
      "16                                  the name professor      6\n",
      "17                                   the name lecturer      6\n",
      "18                                 the name instructor      6\n",
      "19                                    the name teacher      6\n",
      "20                              the name the professor      6\n",
      "21                               the name the lecturer      6\n",
      "22                             the name the instructor      6\n",
      "23                                the name the teacher      6\n",
      "24                               the name of professor      6\n",
      "25                                the name of lecturer      6\n",
      "26                              the name of instructor      6\n",
      "27                                 the name of teacher      6\n",
      "28                           the name of the professor      6\n",
      "29                            the name of the lecturer      6\n",
      "..                                                 ...    ...\n",
      "744                     what is the greensheet of shim      4\n",
      "745               what is the greensheet of shim class      4\n",
      "746             what is the greensheet of shim lecture      4\n",
      "747             what is the greensheet of shim CMPE297      4\n",
      "748                 what is the greensheet of shim 297      4\n",
      "749            what is the greensheet of shim CMPE-297      4\n",
      "750            what is the greensheet of shim CMPE 297      4\n",
      "751       what is the greensheet of shim deep learning      4\n",
      "752               what is the greensheet of simon shim      4\n",
      "753         what is the greensheet of simon shim class      4\n",
      "754       what is the greensheet of simon shim lecture      4\n",
      "755       what is the greensheet of simon shim CMPE297      4\n",
      "756           what is the greensheet of simon shim 297      4\n",
      "757      what is the greensheet of simon shim CMPE-297      4\n",
      "758      what is the greensheet of simon shim CMPE 297      4\n",
      "759  what is the greensheet of simon shim deep lear...      4\n",
      "760                  what is the greensheet of mr shim      4\n",
      "761            what is the greensheet of mr shim class      4\n",
      "762          what is the greensheet of mr shim lecture      4\n",
      "763          what is the greensheet of mr shim CMPE297      4\n",
      "764              what is the greensheet of mr shim 297      4\n",
      "765         what is the greensheet of mr shim CMPE-297      4\n",
      "766         what is the greensheet of mr shim CMPE 297      4\n",
      "767    what is the greensheet of mr shim deep learning      4\n",
      "0                                                  bye      5\n",
      "1                                                  cya      5\n",
      "2                                              goodbye      5\n",
      "3                                               See ya      5\n",
      "4                                              bye-bye      5\n",
      "5                                             good bye      5\n",
      "\n",
      "[5592 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name professor' 'name lecturer' 'name instructor' ..., 'See ya' 'bye-bye'\n",
      " 'good bye']\n",
      "[[6]\n",
      " [6]\n",
      " [6]\n",
      " ..., \n",
      " [5]\n",
      " [5]\n",
      " [5]]\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array(train_data[0])\n",
    "y_train = np.array(train_data['class'])\n",
    "x_test = np.array(train_data[0])\n",
    "y_test = np.array(train_data['class'])\n",
    "print x_train\n",
    "y_train = np.array(y_train).reshape([-1, 1])\n",
    "print y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()\n",
    "vect.fit(x_train)\n",
    "x_train_dtm = vect.transform(x_train)\n",
    "x_test_dtm = vect.transform(x_test)\n",
    "input_size =  len(vect.get_feature_names())\n",
    "#print x_train_dtm\n",
    "simple_train_dtm = vect.transform(x_train)\n",
    "#simple_train_dtm\n",
    "#pd.DataFrame(simple_train_dtm.toarray(), columns=vect.get_feature_names())\n",
    "x_cnn = np.array(simple_train_dtm.toarray(), np.float32)\n",
    "print x_cnn[0]\n",
    "#y_cnn = np.array(tf.one_hot(y_train,6))\n",
    "#print y_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(x_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 468,    0,    0,    0,   12,    0,    0,    0,    0,   19,   61,\n",
       "           0],\n",
       "       [   0,  108,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0],\n",
       "       [   0,    4,    2,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0],\n",
       "       [   0,    0,    0,   80,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0],\n",
       "       [   0,    0,    0,    0,  768,    0,    0,    0,    0,    0,    0,\n",
       "           0],\n",
       "       [   0,    2,    0,    0,    0,    4,    0,    0,    0,    0,    0,\n",
       "           0],\n",
       "       [   0,    0,    0,    0,    0,    0,   88,    0,    0,    0,    8,\n",
       "           0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0, 1032,    0,    0,    0,\n",
       "           0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,   15,  295,    0,    0,\n",
       "           0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,  900,    0,\n",
       "           0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,   15, 1695,\n",
       "           0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    8,\n",
       "           8]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_class = nb.predict(x_test_dtm)\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test, y_pred_class)\n",
    "metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Professor Name\n"
     ]
    }
   ],
   "source": [
    "print class_labels[np.asscalar(nb.predict(x_test_dtm[0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "query = [\"syllabus\"]\n",
    "msg = vect.transform(query)\n",
    "msg =  msg.toarray()\n",
    "print msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syllabus\n"
     ]
    }
   ],
   "source": [
    "print class_labels[np.asscalar(nb.predict(msg))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# input placeholders\n",
    "X = tf.placeholder(tf.float32, [None, input_size])\n",
    "X_img = tf.reshape(X, [-1,1,input_size,1]) \n",
    "y = tf.placeholder(tf.int32, [None, 1])\n",
    "Y = tf.one_hot(y,6)\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
    "L1 = tf.nn.conv2d(X_img, W1,strides=[1, 1, 1, 1], padding='SAME')\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.max_pool(L1,ksize=[1, 2, 2, 1],strides=[1, 2, 2, 1], padding='SAME')\n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "L2 = tf.reshape(L2, [-1, 7 * 7 * 64])\n",
    "W3 = tf.get_variable(\"W3\", shape=[7 * 7 * 64, 6], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b = tf.Variable(tf.random_normal([6]))\n",
    "hypothesis = tf.matmul(L2, W3) + b\n",
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.1).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_class = 12;\n",
    "X = tf.placeholder(tf.float32, [None, input_size])\n",
    "y = tf.placeholder(tf.int32, [None, 1])\n",
    "Y = tf.one_hot(y, n_class)\n",
    "W1 = tf.Variable(tf.truncated_normal([input_size, 256], stddev=math.sqrt(2.0/(28*28))))\n",
    "b1 = tf.Variable(tf.zeros([256]))\n",
    "W2 = tf.Variable(tf.truncated_normal([256, 64], stddev=math.sqrt(2.0/(256))))\n",
    "b2 = tf.Variable(tf.zeros([64]))\n",
    "W3 = tf.Variable(tf.truncated_normal([64, n_class], stddev=math.sqrt(2.0/(64))))\n",
    "b3 = tf.Variable(tf.zeros([n_class]))\n",
    "layer1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "layer2 = tf.nn.relu(tf.matmul(layer1, W2) + b2)\n",
    "hypothesis = tf.nn.relu(tf.matmul(layer2, W3) + b3)\n",
    "prediction = tf.nn.softmax(hypothesis)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=hypothesis))\n",
    "cost_summ = tf.summary.scalar(\"cost\", cost)\n",
    "summary = tf.summary.merge_all()\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=0.03).minimize(cost)\n",
    "is_correct = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning stared. It takes sometime.\n",
      "('Epoch:', '0001', 'cost =', '2.493116617')\n",
      "('Epoch:', '0002', 'cost =', '2.491326094')\n",
      "('Epoch:', '0003', 'cost =', '2.489502907')\n",
      "('Epoch:', '0004', 'cost =', '2.487651825')\n",
      "('Epoch:', '0005', 'cost =', '2.485761642')\n",
      "('Epoch:', '0006', 'cost =', '2.483825684')\n",
      "('Epoch:', '0007', 'cost =', '2.481853962')\n",
      "('Epoch:', '0008', 'cost =', '2.479838848')\n",
      "('Epoch:', '0009', 'cost =', '2.477754831')\n",
      "('Epoch:', '0010', 'cost =', '2.475584984')\n",
      "('Epoch:', '0011', 'cost =', '2.473316669')\n",
      "('Epoch:', '0012', 'cost =', '2.470926762')\n",
      "('Epoch:', '0013', 'cost =', '2.468367577')\n",
      "('Epoch:', '0014', 'cost =', '2.465659142')\n",
      "('Epoch:', '0015', 'cost =', '2.462734699')\n",
      "('Epoch:', '0016', 'cost =', '2.459557056')\n",
      "('Epoch:', '0017', 'cost =', '2.456133842')\n",
      "('Epoch:', '0018', 'cost =', '2.452444792')\n",
      "('Epoch:', '0019', 'cost =', '2.448479652')\n",
      "('Epoch:', '0020', 'cost =', '2.444231272')\n",
      "('Epoch:', '0021', 'cost =', '2.439764023')\n",
      "('Epoch:', '0022', 'cost =', '2.435052395')\n",
      "('Epoch:', '0023', 'cost =', '2.430090904')\n",
      "('Epoch:', '0024', 'cost =', '2.424832582')\n",
      "('Epoch:', '0025', 'cost =', '2.419255972')\n",
      "('Epoch:', '0026', 'cost =', '2.413331032')\n",
      "('Epoch:', '0027', 'cost =', '2.407008410')\n",
      "('Epoch:', '0028', 'cost =', '2.400224686')\n",
      "('Epoch:', '0029', 'cost =', '2.392970085')\n",
      "('Epoch:', '0030', 'cost =', '2.385190248')\n",
      "('Epoch:', '0031', 'cost =', '2.376785517')\n",
      "('Epoch:', '0032', 'cost =', '2.367520571')\n",
      "('Epoch:', '0033', 'cost =', '2.357216835')\n",
      "('Epoch:', '0034', 'cost =', '2.345045090')\n",
      "('Epoch:', '0035', 'cost =', '2.329518557')\n",
      "('Epoch:', '0036', 'cost =', '2.309642315')\n",
      "('Epoch:', '0037', 'cost =', '2.286660671')\n",
      "('Epoch:', '0038', 'cost =', '2.262095928')\n",
      "('Epoch:', '0039', 'cost =', '2.235543966')\n",
      "('Epoch:', '0040', 'cost =', '2.206538439')\n",
      "('Epoch:', '0041', 'cost =', '2.174765587')\n",
      "('Epoch:', '0042', 'cost =', '2.139972210')\n",
      "('Epoch:', '0043', 'cost =', '2.101987600')\n",
      "('Epoch:', '0044', 'cost =', '2.060820580')\n",
      "('Epoch:', '0045', 'cost =', '2.016551018')\n",
      "('Epoch:', '0046', 'cost =', '1.969308257')\n",
      "('Epoch:', '0047', 'cost =', '1.919441104')\n",
      "('Epoch:', '0048', 'cost =', '1.867514253')\n",
      "('Epoch:', '0049', 'cost =', '1.814077020')\n",
      "('Epoch:', '0050', 'cost =', '1.759725571')\n",
      "('Epoch:', '0051', 'cost =', '1.705311179')\n",
      "('Epoch:', '0052', 'cost =', '1.651981711')\n",
      "('Epoch:', '0053', 'cost =', '1.600950360')\n",
      "('Epoch:', '0054', 'cost =', '1.553150654')\n",
      "('Epoch:', '0055', 'cost =', '1.509586096')\n",
      "('Epoch:', '0056', 'cost =', '1.470709682')\n",
      "('Epoch:', '0057', 'cost =', '1.436336398')\n",
      "('Epoch:', '0058', 'cost =', '1.406059623')\n",
      "('Epoch:', '0059', 'cost =', '1.379355192')\n",
      "('Epoch:', '0060', 'cost =', '1.355890989')\n",
      "('Epoch:', '0061', 'cost =', '1.335186243')\n",
      "('Epoch:', '0062', 'cost =', '1.316827893')\n",
      "('Epoch:', '0063', 'cost =', '1.300706387')\n",
      "('Epoch:', '0064', 'cost =', '1.287679791')\n",
      "('Epoch:', '0065', 'cost =', '1.279562354')\n",
      "('Epoch:', '0066', 'cost =', '1.285237312')\n",
      "('Epoch:', '0067', 'cost =', '1.327325106')\n",
      "('Epoch:', '0068', 'cost =', '1.495171547')\n",
      "('Epoch:', '0069', 'cost =', '2.304149151')\n",
      "('Epoch:', '0070', 'cost =', '1.760364771')\n",
      "('Epoch:', '0071', 'cost =', '1.634060144')\n",
      "('Epoch:', '0072', 'cost =', '1.416293621')\n",
      "('Epoch:', '0073', 'cost =', '1.260615349')\n",
      "('Epoch:', '0074', 'cost =', '1.216206193')\n",
      "('Epoch:', '0075', 'cost =', '1.204063892')\n",
      "('Epoch:', '0076', 'cost =', '1.195655107')\n",
      "('Epoch:', '0077', 'cost =', '1.189309716')\n",
      "('Epoch:', '0078', 'cost =', '1.184224129')\n",
      "('Epoch:', '0079', 'cost =', '1.179965258')\n",
      "('Epoch:', '0080', 'cost =', '1.176312923')\n",
      "('Epoch:', '0081', 'cost =', '1.173165083')\n",
      "('Epoch:', '0082', 'cost =', '1.170438409')\n",
      "('Epoch:', '0083', 'cost =', '1.168084145')\n",
      "('Epoch:', '0084', 'cost =', '1.166030049')\n",
      "('Epoch:', '0085', 'cost =', '1.164234877')\n",
      "('Epoch:', '0086', 'cost =', '1.162665844')\n",
      "('Epoch:', '0087', 'cost =', '1.161312342')\n",
      "('Epoch:', '0088', 'cost =', '1.160116553')\n",
      "('Epoch:', '0089', 'cost =', '1.159080267')\n",
      "('Epoch:', '0090', 'cost =', '1.158119202')\n",
      "('Epoch:', '0091', 'cost =', '1.157290936')\n",
      "('Epoch:', '0092', 'cost =', '1.156569242')\n",
      "('Epoch:', '0093', 'cost =', '1.156024218')\n",
      "('Epoch:', '0094', 'cost =', '1.155345201')\n",
      "('Epoch:', '0095', 'cost =', '1.155129433')\n",
      "('Epoch:', '0096', 'cost =', '1.153974533')\n",
      "('Epoch:', '0097', 'cost =', '1.153691649')\n",
      "('Epoch:', '0098', 'cost =', '1.152970433')\n",
      "('Epoch:', '0099', 'cost =', '1.152830601')\n",
      "('Epoch:', '0100', 'cost =', '1.152040601')\n"
     ]
    }
   ],
   "source": [
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# train my model\n",
    "print('Learning stared. It takes sometime.')\n",
    "for epoch in range(100):\n",
    "    avg_cost = 0\n",
    "    #sess.run(y_cnn)\n",
    "    #y_cnn = np.array(tf.one_hot(y_train,6))\n",
    "    #total_batch = int(mnist.train.num_examples / batch_size)   \n",
    "    #for i in range(4064):\n",
    "    #batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "    #for i in range(4064):\n",
    "    #feed_dict = {X: np.array(x_cnn).reshape([1, 32]), Y: np.array(y_cnn[i]).reshape([-1,1])}\n",
    "    feed_dict = {X: x_cnn.reshape([-1, input_size]), y: np.array(y_train)}\n",
    "    s,c, _, = sess.run([summary, cost, optimizer],feed_dict=feed_dict)       \n",
    "    avg_cost += c / 4064\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00297389  0.00297389  0.00297389  0.00297389  0.96728748  0.00297389\n",
      "   0.00297389  0.00297389  0.00297389  0.00297389  0.00297389  0.00297389]]\n"
     ]
    }
   ],
   "source": [
    "print sess.run(prediction, feed_dict = {X:msg})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
